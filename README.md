# Awesome LLM + Fake News Detection üïµÔ∏è‚Äç‚ôÇÔ∏èü§ñ
A curated list of resources, tools, datasets, and research papers for detecting fake news and misinformation using Large Language Models (LLMs).

## üìö Research Papers

#### **Fake News and Misinformation Detection**
- **Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Real-time Fake News from Adversarial Feedback** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Detection of Human and Machine-Authored Fake News in Urdu** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **MemeQA: Holistic Evaluation of Meme Understanding** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Structured Discourse Representation for Factual Consistency Verification** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **EuroVerdict: A Multilingual Dataset for Verdict Generation Against Misinformation** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **'No' Matters: Out-of-Distribution Detection in Multimodality Multi-Turn Interactive Dialogue** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Just KIDDIN' : Knowledge Infusion and Distillation for Detection of INdecent Memes** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **EvoBench: Towards Real-world LLM-Generated Text Detection Benchmarking for Evolving Large Language Models** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)

#### **Fact-Checking and Verification**
- **FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Can Community Notes Replace Professional Fact-Checkers?** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **SYNTHVERIFY: Unleashing the Power of LLMs for Zero-Shot Claim Verification via Step-by-Step Synthetic Data Generation** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **FactLens: Benchmarking Fine-Grained Fact Verification** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **A MISMATCHED Benchmark for Scientific Natural Language Inference** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Core: Robust Factual Precision with Informative Sub-Claim Identification** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **How Does Generation Length Affect Long-Form Factuality** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Long-form Hallucination Detection with Self-elicitation** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)

#### **Misinformation and Disinformation Analysis**
- **How does Misinformation Affect Large Language Model Behaviors and Preferences?** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information** *(ACL 2025 Main)* | [Paper](#) | [Code](#)

#### **Rumor Detection and Social Media Analysis**
- **Text is All You Need: LLM-enhanced Incremental Social Event Detection** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **Conspiracy Theories and Where to Find Them on TikTok** *(ACL 2025 Main)* | [Paper](#) | [Code](#)
- **FGDGNN: Fine-Grained Dynamic Graph Neural Network for Rumor Detection on Social Media** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **MONTROSE: LLM-driven Monte Carlo Tree Search Self-Refinement for Cross-Domain Rumor Detection** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **MultiHoax: A Dataset of Multi-hop False-premise questions** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)

#### **Bias and Harmful Content Detection**
- **Hatevolution: What Static Benchmarks Don't Tell Us** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
- **Measuring Bias and Agreement in Large Language Model Presupposition Judgments** *(ACL 2025 Findings)* | [Paper](#) | [Code](#)
